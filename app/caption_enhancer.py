from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda


class CaptionEnhancer:
    """
    A class to enhance image captions using an LLM
    (e.g., Mistral via Ollama)
    to make them more specific and useful for identifying plant diseases.
    """

    def __init__(self, llm=None):
        # Use provided LLM instance or initialize a default ChatOllama model
        # (e.g., Mistral)
        self.llm = llm or ChatOllama(
            model="mistral", base_url="http://host.docker.internal:11434"
        )

        # Define a prompt template that instructs the LLM
        # to improve the original caption
        self.prompt = PromptTemplate.from_template(
            "You are an expert in plant pathology. "
            "Improve this image caption by making it more specific and helpful for identifying plant diseases:\n\n"
            "Original: {caption}\n\nImproved:"
        )

        # Combine prompt, LLM, and a lambda
        # to extract only the response content
        self.chain = (
            self.prompt | self.llm | RunnableLambda(lambda x: x.content)
        )

    def enhance(self, caption: str) -> str:
        """
        Enhances the input caption using the LLM chain.

        Args:
            caption (str): The original caption generated by BLIP
            or another model.

        Returns:
            str: A refined, domain-aware caption.
        """
        return self.chain.invoke({"caption": caption})
